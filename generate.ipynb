{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x6vFbmtxn_Ju"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9gIsR5SoTbj",
        "outputId": "0c34b75e-4650-47ef-f5bd-0d8a826d65cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/devic1/RNN-/raw/main/data.zip"
      ],
      "metadata": {
        "id": "KplsyYsvodGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb43528-52aa-413a-903a-a2f07d8d2c5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-11 16:30:17--  https://github.com/devic1/RNN-/raw/main/data.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/devic1/RNN-/main/data.zip [following]\n",
            "--2023-02-11 16:30:17--  https://raw.githubusercontent.com/devic1/RNN-/main/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23197 (23K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  22.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-11 16:30:18 (58.9 MB/s) - ‘data.zip’ saved [23197/23197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL-gkXadsa2Y",
        "outputId": "9c7669e5-e0ff-48bb-faa9-22cef29cf1e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/boys.txt           \n",
            "  inflating: data/girls.txt          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import os"
      ],
      "metadata": {
        "id": "9_CYI0H1sdUK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/boys.txt\",\"r\") as f:\n",
        "  data = f.read()\n",
        "data = data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "-mLk6ETLsiBn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezdy8LcO15hB",
        "outputId": "3ec3173b-0531-4faa-d14e-f6ae6dbf2814"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['அகண்டலன்', 'அகத்தியன்', 'அகரன்', 'அகரமுதல்வன்', 'அகற்கண்ணன்']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lett = set()\n",
        "for i in data:\n",
        "  for j in i:\n",
        "    lett.add(j)\n",
        "lett.add(\".\")"
      ],
      "metadata": {
        "id": "2m4S7GNdthEI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ltoi = {i:k for k,i in enumerate(sorted(lett))}\n",
        "ll_n = len(ltoi)\n",
        "print(ltoi)\n",
        "ll_n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3JQ75Ivt9m_",
        "outputId": "e4dd3593-52a3-446c-b171-6c3884ddf35b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, ',': 1, '.': 2, ';': 3, 'ஃ': 4, 'அ': 5, 'ஆ': 6, 'இ': 7, 'உ': 8, 'ஊ': 9, 'எ': 10, 'ஏ': 11, 'ஐ': 12, 'ஒ': 13, 'ஓ': 14, 'க': 15, 'ங': 16, 'ச': 17, 'ஜ': 18, 'ஞ': 19, 'ட': 20, 'ண': 21, 'த': 22, 'ந': 23, 'ன': 24, 'ப': 25, 'ம': 26, 'ய': 27, 'ர': 28, 'ற': 29, 'ல': 30, 'ள': 31, 'ழ': 32, 'வ': 33, 'ஷ': 34, 'ஸ': 35, 'ஹ': 36, 'ா': 37, 'ி': 38, 'ீ': 39, 'ு': 40, 'ூ': 41, 'ெ': 42, 'ே': 43, 'ை': 44, 'ொ': 45, 'ோ': 46, 'ௌ': 47, '்': 48}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itol = {l:k for k,l in ltoi.items()}\n",
        "print(itol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2to2VZrD7sA",
        "outputId": "deb830f5-287d-482a-967d-8af1ab1a03e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ' ', 1: ',', 2: '.', 3: ';', 4: 'ஃ', 5: 'அ', 6: 'ஆ', 7: 'இ', 8: 'உ', 9: 'ஊ', 10: 'எ', 11: 'ஏ', 12: 'ஐ', 13: 'ஒ', 14: 'ஓ', 15: 'க', 16: 'ங', 17: 'ச', 18: 'ஜ', 19: 'ஞ', 20: 'ட', 21: 'ண', 22: 'த', 23: 'ந', 24: 'ன', 25: 'ப', 26: 'ம', 27: 'ய', 28: 'ர', 29: 'ற', 30: 'ல', 31: 'ள', 32: 'ழ', 33: 'வ', 34: 'ஷ', 35: 'ஸ', 36: 'ஹ', 37: 'ா', 38: 'ி', 39: 'ீ', 40: 'ு', 41: 'ூ', 42: 'ெ', 43: 'ே', 44: 'ை', 45: 'ொ', 46: 'ோ', 47: 'ௌ', 48: '்'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,inp_size,hid_size,out_size):\n",
        "    super().__init__()\n",
        "    self.inp_size = inp_size\n",
        "    self.hid_size = hid_size\n",
        "    self.out_size = out_size\n",
        "    self.i2h = nn.Linear(self.inp_size+self.hid_size,self.hid_size)\n",
        "    self.i2o = nn.Linear(self.inp_size+self.hid_size,self.out_size)\n",
        "    self.o2o = nn.Linear(self.hid_size+self.out_size,self.out_size)\n",
        "    self.drop = nn.Dropout(0.1)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self,inp,hid):\n",
        "    combined_out = torch.cat((inp,hid),dim=1)\n",
        "    hid_1 = self.i2h(combined_out)\n",
        "    out = self.i2o(combined_out)\n",
        "    combined_sec = torch.cat((hid_1,out),1)\n",
        "    x = self.o2o(combined_sec)\n",
        "    x = self.drop(x)\n",
        "    x = self.softmax(x)\n",
        "    return x,hid_1\n",
        "\n",
        "  def temp_hidden(self):\n",
        "    return torch.zeros(1,self.hid_size)\n"
      ],
      "metadata": {
        "id": "oG_KoWDluo2_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(ll_n,128,ll_n).to(device)"
      ],
      "metadata": {
        "id": "liwxiVu-yQhP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_enc(lett):\n",
        "  return torch.nn.functional.one_hot(torch.tensor(ltoi[lett]),num_classes=ll_n).unsqueeze(0)"
      ],
      "metadata": {
        "id": "9ZRCrYnSCq3q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lente = len(data)\n",
        "def getrandinp():\n",
        "  randn = torch.randint(0,lente,(1,))\n",
        "  inp = torch.tensor([])\n",
        "  out = torch.tensor([],dtype=torch.long)\n",
        "  word = data[randn]\n",
        "  for i,j in zip(word,word[1:]+\".\"):\n",
        "    tens = one_enc(i)\n",
        "    inp = torch.cat((inp,tens),0)\n",
        "    teno = torch.tensor(ltoi[j]).unsqueeze(0)\n",
        "    out = torch.cat((out,teno))\n",
        "  return inp,out.unsqueeze(1),word"
      ],
      "metadata": {
        "id": "efAeleRcz-R_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(),lr=0.005)"
      ],
      "metadata": {
        "id": "aSsnD6DK7aFY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100000\n",
        "rnn.train()\n",
        "for num in range(epoch):\n",
        "  hid = rnn.temp_hidden()\n",
        "  inp,tar,word = getrandinp()\n",
        "  inp,tar,hid = inp.to(device),tar.to(device),hid.to(device)\n",
        "  loss = 0\n",
        "  for i in range(len(word)):\n",
        "    out,hid = rnn(inp[i].unsqueeze(0),hid)\n",
        "    loss += loss_fn(out,tar[i])\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if num%(epoch/10) == 0:\n",
        "    print(loss/len(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7AjGmTIzFJ2",
        "outputId": "1d8491ec-258f-405f-939b-2dac95ef6e1c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(2.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(1.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(2.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(2.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(2.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(1.7527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(2.5321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(1.3960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.eval()\n",
        "with torch.no_grad():\n",
        "  for i in range(10):\n",
        "    #t = input(\"Enter a continuous letter : \")\n",
        "    t = itol[torch.randint(5,ll_n,(1,)).item()]\n",
        "    hid = rnn.temp_hidden()\n",
        "    hid = hid.to(device)\n",
        "    real_out = \"\"\n",
        "    while True:\n",
        "      n = one_enc(t)\n",
        "      n = n.to(device)\n",
        "      out,hid = rnn(n,hid)\n",
        "      _,result = out.topk(3)\n",
        "      res = result[0][torch.randint(0,3,(1,))].item()\n",
        "      real_out += t\n",
        "      if itol[res] == \".\":\n",
        "        break\n",
        "      t = itol[res]\n",
        "    print(real_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYgyeS538Eaj",
        "outputId": "fea67ee9-d5f6-4d8b-c3dc-e626d08f118c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ஹன் \n",
            "ொலைம்\n",
            "ஹாட்டிய்முபழகுரி\n",
            "ஐனிரன்பன் அறுமைபஙபிருமி\n",
            "ஊமுரசு\n",
            "மாரியாமி\n",
            "உத்சுநந்குறிவார்பன்பி\n",
            "த்ராம்\n",
            "இளஞன்யன்\n",
            "ஊருஜி\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rnn.state_dict(), \"/content/drive/MyDrive/college/rnn_model.pt\")"
      ],
      "metadata": {
        "id": "dsqr-3P9cpCP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Happy Ending :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Qjh_66FpcA",
        "outputId": "cab549ad-280d-4d36-dfe1-6ff72455abc6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy Ending :)\n"
          ]
        }
      ]
    }
  ]
}